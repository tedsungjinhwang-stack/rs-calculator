"""
RS Data Collection Module - Extended Version
í™•ì¥ëœ ë²”ìœ„ë¡œ ë” ë§ì€ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘
"""

import json
import time
from datetime import datetime, timedelta
import pandas as pd
import yfinance as yf
import requests
import yaml

def load_config():
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    with open('config.yaml', 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def get_sp500_tickers():
    """S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸"""
    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    tables = pd.read_html(requests.get(url, headers=headers).text)
    df = tables[0]
    return df['Symbol'].str.replace('.', '-').tolist()

def get_nasdaq100_tickers():
    """Nasdaq 100 ì¢…ëª© ë¦¬ìŠ¤íŠ¸"""
    url = 'https://en.wikipedia.org/wiki/Nasdaq-100'
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    tables = pd.read_html(requests.get(url, headers=headers).text)
    df = tables[4]
    return df['Ticker'].str.replace('.', '-').tolist()

def get_sp400_tickers():
    """S&P 400 (Mid Cap) ì¢…ëª© ë¦¬ìŠ¤íŠ¸"""
    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_400_companies'
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        tables = pd.read_html(requests.get(url, headers=headers).text)
        df = tables[0]
        return df['Symbol'].str.replace('.', '-').tolist()
    except:
        print("âš ï¸  S&P 400 ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
        return []

def get_sp600_tickers():
    """S&P 600 (Small Cap) ì¢…ëª© ë¦¬ìŠ¤íŠ¸"""
    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_600_companies'
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        tables = pd.read_html(requests.get(url, headers=headers).text)
        df = tables[0]
        return df['Symbol'].str.replace('.', '-').tolist()
    except:
        print("âš ï¸  S&P 600 ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
        return []

def get_russell2000_tickers():
    """Russell 2000 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (Wikipediaì—ì„œ)"""
    url = 'https://en.wikipedia.org/wiki/Russell_2000_Index'
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, headers=headers)
        tables = pd.read_html(response.text)

        # Russell 2000 ì „ì²´ ë¦¬ìŠ¤íŠ¸ëŠ” Wikipediaì— ì—†ìŒ
        # ëŒ€ì‹  ìƒìœ„ ì¼ë¶€ë§Œ ìˆì„ ìˆ˜ ìˆìŒ
        if len(tables) > 0:
            df = tables[0]
            if 'Ticker' in df.columns:
                return df['Ticker'].str.replace('.', '-').tolist()
            elif 'Symbol' in df.columns:
                return df['Symbol'].str.replace('.', '-').tolist()
    except Exception as e:
        print(f"âš ï¸  Russell 2000 ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

    return []

def get_nasdaq_screener_tickers(min_market_cap=500000000, max_count=1000):
    """
    Nasdaq ìŠ¤í¬ë¦¬ë„ˆì—ì„œ ì‹œê°€ì´ì•¡ ê¸°ì¤€ ì¢…ëª© ê°€ì ¸ì˜¤ê¸°
    min_market_cap: ìµœì†Œ ì‹œê°€ì´ì•¡ ($)
    max_count: ìµœëŒ€ ì¢…ëª© ìˆ˜
    """
    print(f"ğŸ“Š Nasdaq ìŠ¤í¬ë¦¬ë„ˆì—ì„œ ì‹œê°€ì´ì•¡ ${min_market_cap/1e9:.1f}B ì´ìƒ ì¢…ëª© ìˆ˜ì§‘ ì¤‘...")

    try:
        # Nasdaq FTPì—ì„œ ì „ì²´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ
        url = "ftp://ftp.nasdaqtrader.com/symboldirectory/nasdaqlisted.txt"
        df = pd.read_csv(url, sep='|')

        # ETF ì œì™¸
        df = df[df['ETF'] == 'N']
        tickers = df['Symbol'].tolist()

        print(f"   âœ… {len(tickers)}ê°œ Nasdaq ì¢…ëª© ìˆ˜ì§‘")

        # NYSE ì¶”ê°€
        url_nyse = "ftp://ftp.nasdaqtrader.com/symboldirectory/otherlisted.txt"
        df_nyse = pd.read_csv(url_nyse, sep='|')
        df_nyse = df_nyse[df_nyse['ETF'] == 'N']
        tickers_nyse = df_nyse['ACT Symbol'].tolist()

        print(f"   âœ… {len(tickers_nyse)}ê°œ NYSE ì¢…ëª© ìˆ˜ì§‘")

        all_tickers = tickers + tickers_nyse

        # ì¤‘ë³µ ì œê±° ë° íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
        all_tickers = list(set([t.replace('.', '-') for t in all_tickers if isinstance(t, str) and t.strip()]))

        print(f"   ğŸ“‹ ì´ {len(all_tickers)}ê°œ ì¢…ëª© (ì¤‘ë³µ ì œê±° í›„)")
        print(f"   ğŸ’° ì‹œê°€ì´ì•¡ í•„í„°ë§ ì¤‘... (ìµœì†Œ ${min_market_cap/1e9:.1f}B)")

        # ì‹œê°€ì´ì•¡ìœ¼ë¡œ í•„í„°ë§ (ìƒìœ„ max_countê°œë§Œ)
        # ì£¼ì˜: ëª¨ë“  ì¢…ëª© ì¡°íšŒëŠ” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼
        # ìƒ˜í”Œë§ ë˜ëŠ” ë°°ì¹˜ ì²˜ë¦¬ í•„ìš”

        return all_tickers[:max_count]  # ì„ì‹œë¡œ ìƒìœ„ Nê°œë§Œ ë°˜í™˜

    except Exception as e:
        print(f"âš ï¸  ìŠ¤í¬ë¦¬ë„ˆ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return []

def get_all_tickers(config):
    """ì„¤ì •ì— ë”°ë¼ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘"""
    all_tickers = set()

    # ê¸°ë³¸ ì§€ìˆ˜ë“¤
    if config.get('SP500', False):
        print("ğŸ“Š S&P 500 ì¢…ëª© ìˆ˜ì§‘ ì¤‘...")
        tickers = get_sp500_tickers()
        all_tickers.update(tickers)
        print(f"   âœ… {len(tickers)}ê°œ ì¢…ëª© ìˆ˜ì§‘")

    if config.get('NQ100', False):
        print("ğŸ“Š Nasdaq 100 ì¢…ëª© ìˆ˜ì§‘ ì¤‘...")
        tickers = get_nasdaq100_tickers()
        all_tickers.update(tickers)
        print(f"   âœ… {len(tickers)}ê°œ ì¢…ëª© ìˆ˜ì§‘")

    if config.get('SP400', False):
        print("ğŸ“Š S&P 400 ì¢…ëª© ìˆ˜ì§‘ ì¤‘...")
        tickers = get_sp400_tickers()
        all_tickers.update(tickers)
        print(f"   âœ… {len(tickers)}ê°œ ì¢…ëª© ìˆ˜ì§‘")

    if config.get('SP600', False):
        print("ğŸ“Š S&P 600 ì¢…ëª© ìˆ˜ì§‘ ì¤‘...")
        tickers = get_sp600_tickers()
        all_tickers.update(tickers)
        print(f"   âœ… {len(tickers)}ê°œ ì¢…ëª© ìˆ˜ì§‘")

    # Russell 2000 (í™•ì¥)
    if config.get('INCLUDE_RUSSELL_2000', False):
        print("ğŸ“Š Russell 2000 ì¢…ëª© ìˆ˜ì§‘ ì¤‘...")
        tickers = get_russell2000_tickers()
        if tickers:
            all_tickers.update(tickers)
            print(f"   âœ… {len(tickers)}ê°œ ì¢…ëª© ìˆ˜ì§‘")

    # ì‹œê°€ì´ì•¡ ê¸°ì¤€ (í™•ì¥)
    if config.get('INCLUDE_BY_MARKET_CAP', False):
        min_cap = config.get('MIN_MARKET_CAP', 500000000)
        max_count = config.get('MAX_TICKERS_BY_CAP', 1000)
        tickers = get_nasdaq_screener_tickers(min_cap, max_count)
        if tickers:
            all_tickers.update(tickers)
            print(f"   âœ… ì¶”ê°€ {len(tickers)}ê°œ ì¢…ëª© ìˆ˜ì§‘")

    return sorted(list(all_tickers))

def fetch_stock_data(ticker, start_date, end_date, config):
    """ê°œë³„ ì¢…ëª©ì˜ ê°€ê²© ë°ì´í„° ë° ë©”íƒ€ ì •ë³´ ìˆ˜ì§‘"""
    try:
        stock = yf.Ticker(ticker)

        # ê°€ê²© ë°ì´í„°
        hist = stock.history(start=start_date, end=end_date)

        min_days = config.get('MIN_TRADING_DAYS', 200)
        if hist.empty or len(hist) < min_days:
            return None

        # í‰ê·  ê±°ë˜ëŸ‰ ì²´í¬
        min_volume = config.get('MIN_AVG_VOLUME', 100000)
        if hist['Volume'].mean() < min_volume:
            return None

        # ë©”íƒ€ ì •ë³´
        info = stock.info

        # ë°ì´í„° êµ¬ì¡°í™”
        price_data = []
        for date, row in hist.iterrows():
            price_data.append({
                'date': date.strftime('%Y-%m-%d'),
                'open': float(row['Open']),
                'high': float(row['High']),
                'low': float(row['Low']),
                'close': float(row['Close']),
                'volume': int(row['Volume'])
            })

        result = {
            'ticker': ticker,
            'sector': info.get('sector', 'Unknown'),
            'industry': info.get('industry', 'Unknown'),
            'market_cap': info.get('marketCap', 0),
            'exchange': info.get('exchange', 'Unknown'),
            'prices': price_data
        }

        return result

    except Exception as e:
        return None

def collect_all_data(tickers, config):
    """ëª¨ë“  ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘"""
    end_date = datetime.now()
    start_date = end_date - timedelta(days=400)  # 1ë…„ + ì—¬ìœ 

    print(f"\nğŸ“… ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„: {start_date.date()} ~ {end_date.date()}")
    print(f"ğŸ“Š ì´ {len(tickers)}ê°œ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...\n")

    all_data = []
    success_count = 0

    for idx, ticker in enumerate(tickers, 1):
        if idx % 50 == 0:
            print(f"[{idx}/{len(tickers)}] ì§„í–‰ ì¤‘... (ì„±ê³µ: {success_count})")

        data = fetch_stock_data(ticker, start_date, end_date, config)

        if data:
            all_data.append(data)
            success_count += 1

        # API rate limit ë°©ì§€
        time.sleep(0.3)

    print(f"\nâœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {success_count}/{len(tickers)} ì¢…ëª©")

    return all_data

def save_data(data, filename='data/stock_data.json'):
    """ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    import os
    os.makedirs(os.path.dirname(filename), exist_ok=True)

    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    print(f"ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filename}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*80)
    print("ğŸš€ RS Data Collection (Extended)")
    print("="*80)
    print()

    # ì„¤ì • ë¡œë“œ
    config = load_config()

    # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘
    tickers = get_all_tickers(config)
    print(f"\nğŸ“‹ ì´ {len(tickers)}ê°œ ìœ ë‹ˆí¬ ì¢…ëª©")

    # ë°ì´í„° ìˆ˜ì§‘
    all_data = collect_all_data(tickers, config)

    # ë°ì´í„° ì €ì¥
    save_data(all_data)

    print("\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")

if __name__ == "__main__":
    main()
